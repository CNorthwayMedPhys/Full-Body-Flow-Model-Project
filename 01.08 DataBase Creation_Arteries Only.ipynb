{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb97f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8159a7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f266f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display two point cloud with different colours in one o3d window\n",
    "def display_three_pointclouds(array_1,array_2,array_3,windowname):\n",
    "    p1_pcd = o3d.geometry.PointCloud()\n",
    "    p1_pcd.points = o3d.utility.Vector3dVector(array_1)\n",
    "    p1_pcd.paint_uniform_color([0, 0, 0])\n",
    "\n",
    "\n",
    "    p2_pcd = o3d.geometry.PointCloud()\n",
    "    p2_pcd.points = o3d.utility.Vector3dVector(array_2)\n",
    "    p2_pcd.paint_uniform_color([38/255, 191/255, 214/255])\n",
    "\n",
    "    p3_pcd = o3d.geometry.PointCloud()\n",
    "    p3_pcd.points = o3d.utility.Vector3dVector(array_3)\n",
    "    p3_pcd.paint_uniform_color([140/225, 76/255, 164/225]) \n",
    "    \n",
    "    \n",
    "    concate_pc = np.concatenate((array_1, array_2,array_3),axis = 0)\n",
    "    p1_color = np.asarray(p1_pcd.colors)\n",
    "    p2_color = np.asarray(p2_pcd.colors)\n",
    "    p3_color = np.asarray(p3_pcd.colors)\n",
    "    p4_color = np.concatenate((p1_color,p2_color,p3_color), axis=0)\n",
    "\n",
    "    p4_pcd = o3d.geometry.PointCloud()\n",
    "    p4_pcd.points = o3d.utility.Vector3dVector(concate_pc)\n",
    "    p4_pcd.colors = o3d.utility.Vector3dVector(p4_color)\n",
    "    o3d.visualization.draw_geometries([p4_pcd],window_name = windowname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0609fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_two_pointclouds(array_1,array_2,windowname):\n",
    "    \n",
    "    p1_pcd = o3d.geometry.PointCloud()\n",
    "    p1_pcd.points = o3d.utility.Vector3dVector(array_1)\n",
    "    p1_pcd.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "\n",
    "    p2_pcd = o3d.geometry.PointCloud()\n",
    "    p2_pcd.points = o3d.utility.Vector3dVector(array_2)\n",
    "    p2_pcd.paint_uniform_color([0, 0.706, 1])\n",
    "\n",
    "    \n",
    "    concate_pc = np.concatenate((array_1, array_2),axis = 0)\n",
    "    p1_color = np.asarray(p1_pcd.colors)\n",
    "    p2_color = np.asarray(p2_pcd.colors)\n",
    "\n",
    "    p4_color = np.concatenate((p1_color,p2_color), axis=0)\n",
    "\n",
    "    p4_pcd = o3d.geometry.PointCloud()\n",
    "    p4_pcd.points = o3d.utility.Vector3dVector(concate_pc)\n",
    "    p4_pcd.colors = o3d.utility.Vector3dVector(p4_color)\n",
    "    o3d.visualization.draw_geometries([p4_pcd],window_name = windowname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb34be",
   "metadata": {},
   "source": [
    "The purpose of this function is to take a vessel and determine at which axial distance at which another vessel branches off. Additionally it needs to check to see what the terminus condition of the vessel is and then create the appropriate ending conditions for it whether that be flowing directly into another vessel (continous), branching into multiple vessels (split) or no end condition in which case we will need to apply the 0D end condition (tree).\n",
    "\n",
    "Our first necessary step will be to import the excel file which contains all of the file names and the links between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480136e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\cbnor\\\\Documents\\\\Full Body Flow Model Project\\\\FlowTracker.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m     arteries_sheet \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mCassidy.Northway\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mGitRemoteRepo\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mFlowTracker.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     veins_sheet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCassidy.Northway\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mGitRemoteRepo\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mFlowTracker.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, sheet_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    481\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1652\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1651\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1652\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1525\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1523\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1528\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Cassidy.Northway\\\\GitRemoteRepo\\\\FlowTracker.xlsx'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     veins_sheet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCassidy.Northway\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mGitRemoteRepo\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mFlowTracker.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, sheet_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     arteries_sheet \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mcbnor\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mFull Body Flow Model Project\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mFlowTracker.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     veins_sheet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcbnor\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mFull Body Flow Model Project\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mFlowTracker.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, sheet_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    481\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1652\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1651\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1652\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1656\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1657\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1658\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1659\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1525\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1523\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1528\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1529\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\cbnor\\\\Documents\\\\Full Body Flow Model Project\\\\FlowTracker.xlsx'"
     ]
    }
   ],
   "source": [
    "#Import Excel Sheets\n",
    "try:\n",
    "    arteries_sheet = pd.read_excel('C:\\\\Users\\\\Cassidy.Northway\\\\GitRemoteRepo\\\\FlowTracker.xlsx', sheet_name = 0)\n",
    "    veins_sheet = pd.read_excel('C:\\\\Users\\\\Cassidy.Northway\\\\GitRemoteRepo\\\\FlowTracker.xlsx', sheet_name = 1)\n",
    "except:\n",
    "    arteries_sheet = pd.read_excel('C:\\\\Users\\\\cbnor\\\\Documents\\\\Full Body Flow Model Project\\\\FlowTracker.xlsx', sheet_name = 0)\n",
    "    veins_sheet = pd.read_excel('C:\\\\Users\\\\cbnor\\\\Documents\\\\Full Body Flow Model Project\\\\FlowTracker.xlsx', sheet_name = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select sheet\n",
    "sheet = arteries_sheet\n",
    "#sheet = veins_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab42169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our data frame\n",
    "df = pd.DataFrame(columns=['Name','Centre Axis Array', 'Radius Array','End Condition'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e82f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to define our \n",
    "location = 0\n",
    "\n",
    "#Look at every vessel in the sheet\n",
    "for index in range(52,65):#range(0,sheet.shape[0]):551,\n",
    "\n",
    "    name = sheet.at[index,'Anatomy Name']\n",
    "    file_name = sheet.at[index,'Filename']\n",
    "    \n",
    "    #Determine whether the vessel branches at all\n",
    "    end_point = sheet.at[index,'End Point']\n",
    "\n",
    "    if pd.isna(end_point):\n",
    "        final_condition = 'LW' #indicating that the end condition will be the Lax Wendroff\n",
    "    else:\n",
    "        #If the branches exist then we need to process the \n",
    "        final_condition = end_point.split(',')\n",
    "        final_condition = [s.strip() for s in final_condition]\n",
    "    \n",
    "    #Does the vessel branch (other than the end condition?)\n",
    "    branches = sheet.at[index,'Out Flow']\n",
    "    \n",
    "    if pd.isna(branches):\n",
    "        segement_tag  = False\n",
    "    else:\n",
    "        segement_tag = True\n",
    "        branches = branches.split(',')\n",
    "        branches = [s.strip() for s in branches]\n",
    "        \n",
    "        #Remove end condition branches \n",
    "        if final_condition != 'LW':\n",
    "            for vessels in final_condition:\n",
    "                branches.remove(vessels)\n",
    "\n",
    "    #If there are no segements then we just save the whole thing\n",
    "    if segement_tag == False:\n",
    "        main_branch_filename = file_name + '_fitted_data.npy'\n",
    "    \n",
    "        try:\n",
    "            main_branch_array = np.load('C:\\\\Users\\\\Cassidy.Northway\\\\GitRemoteRepo\\\\FittedVesselsFiles\\\\' + main_branch_filename)\n",
    "        except:\n",
    "            main_branch_array = np.load('C:\\\\Users\\\\cbnor\\\\Documents\\\\Full Body Flow Model Project\\\\FittedVesselsFiles\\\\' + main_branch_filename)\n",
    "        \n",
    "        sub_name =  name + '_0'   \n",
    "        center_sub_array = main_branch_array[:,0:3 ]\n",
    "        radius_array = main_branch_array[:,3 ]\n",
    "        end_condition = final_condition\n",
    "        new_row_seg = {'Name' : sub_name,'Centre Axis Array': center_sub_array, 'Radius Array' : radius_array,'End Condition' : end_condition }\n",
    "        df.loc[len(df)] = new_row_seg\n",
    "                \n",
    "    #If the vessel does segement now we gotta set spicy and determine where it segements for each vessel and which comes first\n",
    "    if segement_tag == True:\n",
    "        seg_df = pd.DataFrame(columns=['Branch Name','Index of Split'])\n",
    "        sub_index = 0\n",
    "        \n",
    "        #Find the file names of the main and branches\n",
    "        main_branch_filename = file_name + '_fitted_data.npy'\n",
    "        branch_filenames = []\n",
    "\n",
    "        #For each of the branching files determine the file name to load in the gile\n",
    "        for i in range(0,len(branches)):\n",
    "            branch_name = branches[i]\n",
    "            try:\n",
    "                vessel_row = sheet[sheet['Anatomy Name'].str.match(branch_name)].index.values[0]\n",
    "            except:\n",
    "                print(sheet[sheet['Anatomy Name'].str.match(branch_name)].index.values, branch_name)\n",
    "                    \n",
    "            branch_filename = sheet.at[sheet.index[vessel_row],'Filename']\n",
    "            branch_filename = branch_filename + '_fitted_data.npy'\n",
    "            branch_filenames.append(branch_filename)\n",
    "\n",
    "        #Now we import all of the vessel file\n",
    "        try:\n",
    "            main_branch_array = np.load('C:\\\\Users\\\\Cassidy.Northway\\\\GitRemoteRepo\\\\FittedVesselsFiles\\\\' + main_branch_filename)\n",
    "        except:\n",
    "            main_branch_array = np.load('C:\\\\Users\\\\cbnor\\\\Documents\\\\Full Body Flow Model Project\\\\FittedVesselsFiles\\\\' + main_branch_filename)\n",
    "\n",
    "        for i in range(0,len(branches)):\n",
    "            branch_filename = branch_filenames[i]\n",
    "            branch_name = branches[i]\n",
    "        \n",
    "            try:\n",
    "                branch_array = np.load('C:\\\\Users\\\\Cassidy.Northway\\\\GitRemoteRepo\\\\FittedVesselsFiles\\\\' + branch_filename)\n",
    "            except:\n",
    "                branch_array = np.load('C:\\\\Users\\\\cbnor\\\\Documents\\\\Full Body Flow Model Project\\\\FittedVesselsFiles\\\\' + branch_filename)\n",
    "\n",
    "            #display_two_pointclouds(main_branch_array[:,0:3],branch_array[:,0:3], branch_name)\n",
    "            \n",
    "            #Find the nearest points\n",
    "            dist_array = scipy.spatial.distance.cdist(main_branch_array[:,0:3],branch_array[:,0:3])\n",
    "            dist_array = dist_array[:,0]\n",
    "            index_split = np.where (np.min(dist_array) == dist_array)[0]\n",
    "            seg_df.loc[len(seg_df)] = {'Branch Name': branch_name , 'Index of Split': index_split[0]}\n",
    "        \n",
    "        #We now have the number of off branching vessels and where they branch so now we need to now save the \n",
    "        #segements and off branches and sort segment frame by distance along vessel\n",
    "\n",
    "        seg_df = seg_df.sort_values(by ='Index of Split')\n",
    "        seg_df = seg_df.reset_index(drop=True)\n",
    "        intial_index = 0\n",
    "\n",
    "\n",
    "        for i in range(0,len(seg_df)+1):\n",
    "            if i != len(seg_df):\n",
    "                sub_name =  name + '_' + str(i)\n",
    "                final_index = seg_df.at [ i , 'Index of Split']\n",
    "                center_sub_array = main_branch_array[intial_index:final_index+1,0:3 ]\n",
    "                radius_array = main_branch_array[intial_index:final_index,3 ]\n",
    "                \n",
    "                #p4_pcd = o3d.geometry.PointCloud()\n",
    "                #p4_pcd.points = o3d.utility.Vector3dVector(center_sub_array)\n",
    "                #o3d.visualization.draw_geometries([p4_pcd])\n",
    "                \n",
    "                end_condition = [name + '_' + str(i+1), branches[i]+'_0' ]\n",
    "                new_row_seg = {'Name' : sub_name,'Centre Axis Array': center_sub_array, 'Radius Array' : radius_array,'End Condition' : end_condition }\n",
    "                if not radius_array.any():\n",
    "                    print(new_row_seg\n",
    "                df.loc[len(df)] = new_row_seg\n",
    "                intial_index = final_index\n",
    "                \n",
    "            else:\n",
    "                sub_name =  name + '_' + str(i)\n",
    "                final_index = -1\n",
    "                center_sub_array = main_branch_array[intial_index:final_index,0:3 ]\n",
    "                radius_array = main_branch_array[intial_index:final_index,3 ]\n",
    "                \n",
    "                #p4_pcd = o3d.geometry.PointCloud()\n",
    "                #p4_pcd.points = o3d.utility.Vector3dVector(center_sub_array)\n",
    "                #o3d.visualization.draw_geometries([p4_pcd])\n",
    "                \n",
    "                if not radius_array.any():\n",
    "                    print(new_row_seg)\n",
    "                if final_condition != 'LW':\n",
    "                    end_condition = [final_condition[0] +'_0']\n",
    "                else:\n",
    "                    end_condition = final_condition\n",
    "                new_row_seg = {'Name' : sub_name,'Centre Axis Array': center_sub_array, 'Radius Array' : radius_array,'End Condition' : end_condition }\n",
    "                df.loc[len(df)] = new_row_seg\n",
    "print(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3fe70",
   "metadata": {},
   "source": [
    "## Reassess end conditions\n",
    "\n",
    "We want to go through rows and change the end condition from the name of the vessel segement to the index of those vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46081d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If any vessels end with a single split then I want to combine them into a single vessel before altering \n",
    "#everybodies index number\n",
    "removal_indices=[]\n",
    "for i in range (0,len(df)):\n",
    "    end_condition = df.at[i,'End Condition']\n",
    "    if end_condition != 'LW' and len(end_condition)==1:\n",
    "        index = df[df['Name']==end_condition[0]].index[0]\n",
    "        name = df.at[i,'Name']\n",
    "        centre_array = np.append(df.at[i,'Centre Axis Array'],df.at[index,'Centre Axis Array'],axis = 0)\n",
    "        radius_array = np.append(df.at[i,'Radius Array'],df.at[index,'Radius Array'],axis = 0)\n",
    "        new_end_condition = df.at[index,'End Condition']\n",
    "        new_row_seg = {'Name' : name,'Centre Axis Array': centre_array, 'Radius Array' : radius_array,'End Condition' : new_end_condition }\n",
    "        df.loc[len(df)] = new_row_seg\n",
    "        removal_indices.append(i)\n",
    "        removal_indices.append(index)\n",
    "        \n",
    "\n",
    "print(removal_indices)\n",
    "\n",
    "df = df.drop(df.index[removal_indices])\n",
    "df = df.reset_index(drop=True)\n",
    "display(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac98f82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle('larm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3501875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trouble shooting \n",
    "\n",
    "#array_1 = main_branch_array[0:50,0:3 ]\n",
    "#array_2 = main_branch_array[51:125,0:3 ]\n",
    "#array_3 = main_branch_array[126:-1,0:3 ]\n",
    "#display_three_pointclouds(array_1,array_2,array_3,'Troubleshoot')\n",
    "\n",
    "display_three_pointclouds(df.at[1,'Centre Axis Array'],df.at[2,'Centre Axis Array'],df.at[20,'Centre Axis Array'],'blarg')\n",
    "\n",
    "\n",
    "#p4_pcd = o3d.geometry.PointCloud()\n",
    "#p4_pcd.points = o3d.utility.Vector3dVector(main_branch_array[0:50,0:3 ])\n",
    "#o3d.visualization.draw_geometries([p4_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3344d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(main_branch_array[:,0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391f7dc2",
   "metadata": {},
   "source": [
    "### From here below we will convert the database to be useful for VamPy. Central axis array will become lam = L/Ru, radius array = [Ru,Rd], add we will add k values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d042c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our data frame\n",
    "df_vampy = pd.DataFrame(columns=['Name','lam', 'Radius Values','End Condition','k Array'])\n",
    "\n",
    "#Percentile of radius values used to determine Ru and Rd\n",
    "percent = 0.05 #5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5958e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    name = df.at[i,'Name']\n",
    "    end_condition = df.at[i, 'End Condition']\n",
    "    \n",
    "    #Determine the radius values\n",
    "    radius_values = df.at[i, 'Radius Array']\n",
    "    index_rounding= np.round(len(radius_values)*percent).astype(int)+1\n",
    "    Ru = np.mean(radius_values[0:index_rounding])\n",
    "    \n",
    "    Rd = np.mean(radius_values[-index_rounding:-1])\n",
    "    radius_array = [Ru, Rd]\n",
    "    \n",
    "    #Determine total distance of the vessel\n",
    "    centeral_axis_array = df.at[i,'Centre Axis Array']\n",
    "    total_distance = 0\n",
    "    \n",
    "    for j in range(0,np.shape(centeral_axis_array)[0]-1):\n",
    "        dist = np.linalg.norm(centeral_axis_array[j,:] - centeral_axis_array[j+1,:])\n",
    "        total_distance = total_distance + dist\n",
    "    lam_value = total_distance / Ru \n",
    "    \n",
    "    #Determine the k values (using parameters from 2015_Maynards):\n",
    "    if 'pulmonary' in name:\n",
    "        k_values = [1.3e6, -7, 12.2e4]\n",
    "    elif Ru < 3: #less than 0.3 cm ak 3mm\n",
    "        k_values = [20e6, -22.5, 86.5e4]\n",
    "    else:\n",
    "        k_values = [3e6, -9, 33.7e4]\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    #Write the new row\n",
    "    new_row_seg = {'Name' : name,'lam': lam_value, 'Radius Values' : radius_array,'End Condition' : end_condition, 'k Array' : k_values }           \n",
    "    df_vampy.loc[len(df_vampy)] = new_row_seg\n",
    "                \n",
    "display(df_vampy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_vampy.to_pickle('larm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846ac28",
   "metadata": {},
   "source": [
    "## Time to reorder the vessels to actually descend in order of \"depth\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac23908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordered = pd.DataFrame(columns=['Name','lam', 'Radius Values','End Condition','k Array'])\n",
    "\n",
    "#FOR LARM\n",
    "\n",
    "index_0 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648a28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Save first vessel\n",
    "df_ordered.loc[0]=df_vampy.loc[index_0]\n",
    "next_layer = df_ordered.at[0,'End Condition']\n",
    "while len(next_layer)>0:\n",
    "    next_layer_1 = []\n",
    "    for daughter in next_layer:\n",
    "        index = df_vampy[df_vampy['Name']==daughter].index.values[0]\n",
    "        df_ordered.loc[len(df_ordered)] = df_vampy.loc[index]\n",
    "        end_condition = df_vampy.at[index, 'End Condition']\n",
    "        \n",
    "        if end_condition !='LW':\n",
    "            \n",
    "            next_layer_1 = np.append(next_layer_1, end_condition)\n",
    "        next_layer = next_layer_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86680456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename everyhting by index#\n",
    "\n",
    "for i in range (0,len(df_ordered)):\n",
    "    end_condition = df_ordered.at[i,'End Condition']\n",
    "    if end_condition != 'LW':\n",
    "        replacement = []\n",
    "        if isinstance(end_condition[0], str): \n",
    "            for j in range(0,len(end_condition)):\n",
    "                condition = end_condition[j]\n",
    "                try: \n",
    "                    index = df_ordered[df_ordered['Name']==condition].index.values[0]\n",
    "                except:\n",
    "                    print(condition)\n",
    "                    \n",
    "                replacement.append(index)\n",
    "            df_ordered.at[i,'End Condition'] = replacement \n",
    "            \n",
    "display(df_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aba435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ordered.to_pickle('larm.pkl')\n",
    "for i in range(5,22):\n",
    "    radiusArray = df.loc[i, 'Radius Array']\n",
    "    nx = np.shape(radiusArray)[0]\n",
    "    lam = df_vampy.loc[i, 'lam']\n",
    "    radiusValues = df_vampy.loc[i,'Radius Values']\n",
    "    Ru = radiusValues[0]\n",
    "    Rd = radiusValues[1]\n",
    "    L = lam * Ru\n",
    "    X = np.linspace(0,L,nx)\n",
    "    R = Ru * np.power((Rd/Ru),X/L)\n",
    "    R =Ru*np.exp(j*np.log(Rd/Ru)*(X/L))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(X,R, label = \"Simplified Radii Values\", c = 'darkorchid')\n",
    "    plt.plot(X, radiusArray, label = 'Fitted Radii Values', c = 'darkorchid', ls = 'dotted')\n",
    "    plt.figlegend(loc='upper right', bbox_to_anchor=(0.85, 0.85))\n",
    "    labels = [None]*len(X)\n",
    "    labels[0] = 0\n",
    "    labels[-1] = 'L'\n",
    "\n",
    "\n",
    "    plt.xticks(ticks = [0,L], labels = [0,'L'])\n",
    "    plt.yticks([],[])\n",
    "    plt.xlabel('Position along Vessel Length')\n",
    "    plt.ylabel('Radius of Vessel')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
